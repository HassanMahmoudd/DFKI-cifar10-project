{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# load the pre-shuffled train and test data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# rescale [0,255] --> [0,1]\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255 \n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# break training set into training and validation sets\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# print shape of training set\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_valid.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True) # randomly flip images horizontally\n",
    "\n",
    "# fit augmented image generator on data\n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               512500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 528,054\n",
      "Trainable params: 528,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 1.34030, saving model to aug_model.weights.best.hdf5\n",
      " - 25s - loss: 1.6731 - acc: 0.3926 - val_loss: 1.3403 - val_acc: 0.5200\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss improved from 1.34030 to 1.20360, saving model to aug_model.weights.best.hdf5\n",
      " - 26s - loss: 1.4098 - acc: 0.4913 - val_loss: 1.2036 - val_acc: 0.5744\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss improved from 1.20360 to 1.06835, saving model to aug_model.weights.best.hdf5\n",
      " - 26s - loss: 1.2899 - acc: 0.5387 - val_loss: 1.0684 - val_acc: 0.6196\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss improved from 1.06835 to 1.05189, saving model to aug_model.weights.best.hdf5\n",
      " - 28s - loss: 1.2218 - acc: 0.5654 - val_loss: 1.0519 - val_acc: 0.6384\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss improved from 1.05189 to 1.00184, saving model to aug_model.weights.best.hdf5\n",
      " - 27s - loss: 1.1828 - acc: 0.5815 - val_loss: 1.0018 - val_acc: 0.6464\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss improved from 1.00184 to 0.99436, saving model to aug_model.weights.best.hdf5\n",
      " - 27s - loss: 1.1514 - acc: 0.5944 - val_loss: 0.9944 - val_acc: 0.6568\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 28s - loss: 1.1345 - acc: 0.6045 - val_loss: 1.0388 - val_acc: 0.6400\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss improved from 0.99436 to 0.93801, saving model to aug_model.weights.best.hdf5\n",
      " - 27s - loss: 1.1327 - acc: 0.6076 - val_loss: 0.9380 - val_acc: 0.6808\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss improved from 0.93801 to 0.90033, saving model to aug_model.weights.best.hdf5\n",
      " - 27s - loss: 1.1231 - acc: 0.6131 - val_loss: 0.9003 - val_acc: 0.6934\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 30s - loss: 1.1277 - acc: 0.6128 - val_loss: 0.9446 - val_acc: 0.6770\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 28s - loss: 1.1461 - acc: 0.6098 - val_loss: 0.9625 - val_acc: 0.6762\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 28s - loss: 1.1533 - acc: 0.6098 - val_loss: 0.9983 - val_acc: 0.6692\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 27s - loss: 1.1561 - acc: 0.6059 - val_loss: 0.9408 - val_acc: 0.6774\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 27s - loss: 1.1725 - acc: 0.6016 - val_loss: 1.1489 - val_acc: 0.6192\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 27s - loss: 1.1833 - acc: 0.5946 - val_loss: 0.9671 - val_acc: 0.6714\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 27s - loss: 1.1927 - acc: 0.5981 - val_loss: 0.9901 - val_acc: 0.6692\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 26s - loss: 1.2065 - acc: 0.5916 - val_loss: 1.0781 - val_acc: 0.6496\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 26s - loss: 1.2116 - acc: 0.5895 - val_loss: 0.9402 - val_acc: 0.6884\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 27s - loss: 1.2393 - acc: 0.5791 - val_loss: 0.9724 - val_acc: 0.6672\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 27s - loss: 1.2446 - acc: 0.5838 - val_loss: 1.1988 - val_acc: 0.6176\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 27s - loss: 1.2549 - acc: 0.5782 - val_loss: 1.0379 - val_acc: 0.6564\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 27s - loss: 1.2712 - acc: 0.5742 - val_loss: 1.0458 - val_acc: 0.6384\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 27s - loss: 1.2822 - acc: 0.5671 - val_loss: 1.1159 - val_acc: 0.6260\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 27s - loss: 1.3032 - acc: 0.5621 - val_loss: 1.0199 - val_acc: 0.6614\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 28s - loss: 1.3113 - acc: 0.5572 - val_loss: 1.0287 - val_acc: 0.6480\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 27s - loss: 1.3256 - acc: 0.5527 - val_loss: 1.1103 - val_acc: 0.6342\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 27s - loss: 1.3389 - acc: 0.5531 - val_loss: 1.1076 - val_acc: 0.6260\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 27s - loss: 1.3552 - acc: 0.5463 - val_loss: 1.2018 - val_acc: 0.6074\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 27s - loss: 1.3726 - acc: 0.5401 - val_loss: 1.0704 - val_acc: 0.6298\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 26s - loss: 1.3793 - acc: 0.5365 - val_loss: 1.1123 - val_acc: 0.6368\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 27s - loss: 1.3821 - acc: 0.5359 - val_loss: 1.1223 - val_acc: 0.6020\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 26s - loss: 1.4084 - acc: 0.5263 - val_loss: 1.0304 - val_acc: 0.6550\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 27s - loss: 1.4002 - acc: 0.5254 - val_loss: 1.2006 - val_acc: 0.5980\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 29s - loss: 1.4007 - acc: 0.5275 - val_loss: 1.1343 - val_acc: 0.6080\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 30s - loss: 1.4313 - acc: 0.5190 - val_loss: 1.3779 - val_acc: 0.5134\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 29s - loss: 1.4358 - acc: 0.5147 - val_loss: 1.0703 - val_acc: 0.6246\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 28s - loss: 1.4557 - acc: 0.5076 - val_loss: 1.2513 - val_acc: 0.5658\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 28s - loss: 1.4660 - acc: 0.5055 - val_loss: 1.2756 - val_acc: 0.5718\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 28s - loss: 1.4817 - acc: 0.5036 - val_loss: 1.2498 - val_acc: 0.5686\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 28s - loss: 1.4733 - acc: 0.5026 - val_loss: 1.2476 - val_acc: 0.5880\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 29s - loss: 1.5009 - acc: 0.4944 - val_loss: 1.2205 - val_acc: 0.5800\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 31s - loss: 1.5077 - acc: 0.4878 - val_loss: 1.3240 - val_acc: 0.5290\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 29s - loss: 1.5362 - acc: 0.4837 - val_loss: 1.1579 - val_acc: 0.6122\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 30s - loss: 1.5341 - acc: 0.4871 - val_loss: 2.1235 - val_acc: 0.4534\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 30s - loss: 1.5470 - acc: 0.4790 - val_loss: 1.4426 - val_acc: 0.5370\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 30s - loss: 1.5529 - acc: 0.4756 - val_loss: 1.3208 - val_acc: 0.5614\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 30s - loss: 1.5792 - acc: 0.4677 - val_loss: 1.3244 - val_acc: 0.5354\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 30s - loss: 1.6049 - acc: 0.4598 - val_loss: 1.3668 - val_acc: 0.5046\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 30s - loss: 1.6112 - acc: 0.4544 - val_loss: 1.2489 - val_acc: 0.5798\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 29s - loss: 1.6110 - acc: 0.4562 - val_loss: 1.4660 - val_acc: 0.5098\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 29s - loss: 1.6227 - acc: 0.4461 - val_loss: 1.4369 - val_acc: 0.4752\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 31s - loss: 1.6286 - acc: 0.4462 - val_loss: 1.2512 - val_acc: 0.5728\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 29s - loss: 1.6356 - acc: 0.4403 - val_loss: 1.6888 - val_acc: 0.4152\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 30s - loss: 1.6470 - acc: 0.4359 - val_loss: 1.4789 - val_acc: 0.4778\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 31s - loss: 1.6398 - acc: 0.4412 - val_loss: 1.4163 - val_acc: 0.4696\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 29s - loss: 1.6572 - acc: 0.4315 - val_loss: 1.4186 - val_acc: 0.4986\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 28s - loss: 1.6670 - acc: 0.4275 - val_loss: 1.4326 - val_acc: 0.5154\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 27s - loss: 1.6707 - acc: 0.4217 - val_loss: 1.5090 - val_acc: 0.4608\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 27s - loss: 1.6649 - acc: 0.4255 - val_loss: 1.3305 - val_acc: 0.5416\n",
      "Epoch 60/100\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='aug_model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs, verbose=2, callbacks=[checkpointer],\n",
    "                    validation_data=(x_valid, y_valid),\n",
    "                    validation_steps=x_valid.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('aug_model.weights.best.hdf5')\n",
    "\n",
    "# evaluate and print test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(model, \"tfjs\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DFKI-cifar10]",
   "language": "python",
   "name": "conda-env-DFKI-cifar10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
